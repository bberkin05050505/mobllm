defaults:
  - model: llama3.1-8.0B-Q4_K_M
  - experiment: standard
  - logger: default_logger
  - _self_

# Experiment
output_dir: finals_v1 # Output directory where all runs will be saved, with the following structure: output_dir/benchmark_name/experiment_name/model_name/run_id
max_retries: 5 # Maximum number of retries if prompt failed to generate a valid function as the output
force_valid: false # Force the output to be valid (i.e. a valid function). If false, when the model fails to generate a valid function, after max_retries, the output will be the best generated function so far
force_unique: false # Force the output to be unique (i.e. different from all the functions in the prompt)
prompts_path: prompts # path to promts
prompt_folder: ed_and_sr # prompts folder name
sr_prompt_name: basic_sr.txt
ed_prompt_name: basic_ed.txt
ed_initial_prompt_name: init_ed.txt
max_points_in_prompt: 40 # Maximum number of points in the prompt (if more are provided, they will automatically be downsampled)
checkpoints: [50, 100, 200, 300, 400, 500, 600, 700, 800, 900] # Partial results will be saved at these iterations
allowed_exp_types: 
  - "random_ed_baseline" 
  - "base_ed_and_sr"
  - "base_ed_and_sr_different_prompts"
  - "cost_change_in_prompts"
  - "bayesian_ed"
  - "prompt_optimization"

# Torch
device: 'cuda' # auto works for both CPU and GPU and can be used in a multi-GPU setup
use_bfloat16: false
seed: -1 # If -1, the seed will be randomly generated
random_seed_each_run: true # If true, each run will have a different seed, otherwise the same seed will be used for all runs

# Project root
root: "" # Path to the root of the project, where the 'conf', 'data' directories are located and where main.py is executed

# Plotter
plotter:
  save_video: true
  save_frames: false
  gif_duration: 1000
  plotter_resolution: 1000
  plotter_fig_size: 10

# Parameters for ED and SR experiments

# initialization parameters
initialization:
  num_init_pts_k: 7
  num_test_pts_m: 100
  num_exps_l: 8
  epsilon_c: 0.95
  epsilon_r: 0.99
  test_domain_d: [0, 3]
  num_data_digits: 3
  exp_type: random_ed_baseline

# ED parameters
ED:
  train_domain_d: [0, 1.5]
  exp_budget_n: 5
  retries: 10

# SR parameters
SR:
  num_to_sample_b: 3
  num_best_funcs_c: 3
